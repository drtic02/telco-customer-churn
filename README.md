# ğŸ“Š Telco Customer Churn Prediction

A comprehensive machine learning project to predict customer churn for a telecommunications company using advanced data science techniques.

## ğŸ¯ Project Objective

This project implements a complete data science workflow to predict which customers are likely to churn (cancel their service). The goal is to provide actionable business insights and enable proactive customer retention strategies.

## ğŸ“ˆ Key Results

- **Best Model**: Gradient Boosting (Advanced Model)
- **F1-Score**: 0.628 (primary metric) - *4% improvement over baseline*
- **ROC AUC**: 0.840
- **Overall Accuracy**: 77.2%
- **Precision**: 55.3% (when model predicts churn, it's correct 55% of the time)
- **Recall**: 72.7% (model correctly identifies 73% of customers who will churn)

### Advanced Model Performance
- **Cross-Validation F1-Score**: 0.840 (Â±0.014) - Robust performance validation
- **Cross-Validation ROC-AUC**: 0.915 (Â±0.006) - Excellent discriminative ability

## ğŸ—ï¸ Project Structure

```
TELCO CHURN PROJECT/
â”œâ”€â”€ 01_data_exploration_and_cleaning.ipynb    # Data exploration and preprocessing
â”œâ”€â”€ 02_feature_engineering_and_modeling.ipynb # Feature engineering and model training
â”œâ”€â”€ 03_model_evaluation_and_analysis.ipynb    # Model evaluation and business insights
â”œâ”€â”€ 04_advanced_model_improvement.ipynb       # Advanced modeling and optimization
â”œâ”€â”€ requirements.txt                          # Project dependencies
â”œâ”€â”€ OutlineProject.txt                        # Project mission brief
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ WA_Fn-UseC_-Telco-Customer-Churn.csv
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ churn_data_cleaned.csv
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ best_churn_model.pkl                 # Baseline trained model with preprocessor
â”‚   â””â”€â”€ best_advanced_churn_model.pkl        # Advanced optimized model
â””â”€â”€ reports/
    â””â”€â”€ figures/
        â”œâ”€â”€ confusion_matrix.png             # Model performance visualization
        â”œâ”€â”€ feature_importance.png           # Feature importance analysis
        â”œâ”€â”€ roc_pr_curves.png               # ROC and Precision-Recall curves
        â”œâ”€â”€ advanced_model_comparison.png    # Advanced models performance comparison
        â””â”€â”€ feature_importance_*.png         # Individual model feature importance
```

## ğŸ”¬ Methodology

### Phase 1: Data Exploration & Cleaning
- **Input**: Raw telco customer data (7,043 customers, 21 features)
- **Key Actions**:
  - Fixed data type issues (`TotalCharges` converted from string to numeric)
  - Handled missing values (11 null values imputed with 0 for new customers)
  - Removed non-predictive features (`customerID`)
  - Exploratory data analysis and visualization

### Phase 2: Feature Engineering & Modeling
- **Preprocessing**: StandardScaler for numerical features, OneHotEncoder for categorical features
- **Models Trained**:
  - Logistic Regression
  - Random Forest Classifier
  - XGBoost Classifier
- **Evaluation Metric**: F1-Score (optimized for imbalanced dataset)
- **Data Split**: 80% training, 20% testing (stratified)

### Phase 3: Model Evaluation & Analysis
- Comprehensive performance metrics
- Feature importance analysis
- Business insights and recommendations

### Phase 4: Advanced Model Improvement
- **Advanced Feature Engineering**: Created 12 new features (customer value, lifecycle, service usage)
- **Hyperparameter Optimization**: RandomizedSearchCV for model tuning
- **Class Imbalance Handling**: SMOTE oversampling technique
- **Ensemble Methods**: Voting classifiers for robust predictions
- **Cross-Validation**: 5-fold stratified validation
- **Advanced Algorithms**: Gradient Boosting, LightGBM, XGBoost optimization
- **Performance Improvement**: 4% increase in F1-Score over baseline

## ğŸ¯ Key Predictive Features

1. **TotalCharges** (15.97%) - Customer's total spend with company
2. **Tenure** (13.96%) - Length of customer relationship
3. **MonthlyCharges** (13.71%) - Monthly subscription cost
4. **Month-to-month Contract** (5.00%) - Contract flexibility indicator
5. **No Online Security** (3.28%) - Lack of security services

## ğŸ’¼ Business Insights & Recommendations

### ğŸš¨ High-Risk Customer Profile
- **Short tenure** (< 12 months) + **High monthly charges**
- **Month-to-month contracts**
- **Missing security services**
- **Fiber optic internet** + **Electronic payment methods**

### ğŸ’¡ Retention Strategies

#### 1. Product & Service Improvements
- **Promote longer-term contracts** with attractive incentives
- **Bundle security services** as default offerings
- **Review pricing strategy** for high monthly charge customers

#### 2. Customer Segmentation
- **High Risk**: Short tenure + High charges + Month-to-month + No security
- **Medium Risk**: Medium tenure + Fiber optic + Electronic payment
- **Low Risk**: Long tenure + Lower charges + Long-term contracts

#### 3. Proactive Interventions
- **Early Warning System**: Deploy model to score customers monthly
- **Targeted Offers**: Personalized retention campaigns for high-risk segments
- **Customer Success**: Proactive outreach to customers with tenure < 12 months

### ğŸ“Š Expected Business Impact
- **Reduce churn rate** by 15-20% through targeted interventions
- **Improve customer lifetime value** by extending average tenure
- **Optimize marketing spend** by focusing on high-risk customers
- **Increase revenue** through better retention and contract upgrades

## ğŸš€ Getting Started

### Prerequisites
- Python 3.7+
- Jupyter Notebook or JupyterLab

### Installation

1. **Clone the repository** (or download the project files)
2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

### Dependencies
```
pandas>=1.3.0
numpy>=1.21.0
matplotlib>=3.4.0
seaborn>=0.11.0
scikit-learn>=1.0.0
xgboost>=1.5.0
lightgbm>=3.3.0
imbalanced-learn>=0.8.0
joblib>=1.1.0
```

### Usage

1. **Data Exploration**: Run `01_data_exploration_and_cleaning.ipynb`
2. **Model Training**: Run `02_feature_engineering_and_modeling.ipynb`
3. **Model Evaluation**: Run `03_model_evaluation_and_analysis.ipynb`
4. **Advanced Optimization**: Run `04_advanced_model_improvement.ipynb`

## ğŸ“ Model Details

### Performance Metrics (Advanced Model)
- **Sensitivity (Recall)**: 72.7% - Successfully identifies 73% of churning customers (*17% improvement*)
- **Specificity**: 81.4% - Correctly identifies 81% of non-churning customers
- **Precision**: 55.3% - Moderate false positive rate for churn predictions
- **F1-Score**: 0.628 - Improved balance between precision and recall
- **ROC AUC**: 0.840 - Excellent discriminative ability
- **Cross-Validation Stability**: F1 0.840 (Â±0.014), ROC-AUC 0.915 (Â±0.006)

### Advanced Model Features
- **12 Engineered Features**: Customer value metrics, lifecycle indicators, service usage patterns
- **SMOTE Sampling**: Balanced training data for better minority class detection
- **Hyperparameter Optimization**: Fine-tuned parameters using RandomizedSearchCV
- **Ensemble Approach**: Voting classifier combining multiple algorithms

### Model Deployment Recommendations
- Use the advanced Gradient Boosting model for production deployment
- Set probability threshold at ~0.5 for balanced precision/recall
- Implement ensemble predictions for critical business decisions
- Review model predictions monthly and adjust strategies
- A/B test retention campaigns on predicted high-risk customers
- Monitor model performance and feature drift with cross-validation metrics
- Retrain quarterly with new data using the established pipeline

## ğŸ“Š Visualizations

The project generates several key visualizations:

1. **Confusion Matrix** - Model prediction accuracy breakdown
2. **Feature Importance** - Which factors most influence churn
3. **ROC & PR Curves** - Model performance across different thresholds
4. **Advanced Model Comparison** - Performance comparison across multiple algorithms
5. **Individual Model Feature Importance** - Detailed feature analysis per algorithm

## ï¿½ Advanced Model Achievements

### Performance Improvements
- **4% F1-Score Improvement**: From 0.604 to 0.628
- **17% Recall Improvement**: From 55.9% to 72.7% (better churn detection)
- **Robust Cross-Validation**: 5-fold validation with F1-Score 0.840 (Â±0.014)
- **Multiple Algorithm Testing**: Gradient Boosting outperformed 5 other advanced models

### Technical Innovations
- **Advanced Feature Engineering**: 12 new features including customer value metrics, lifecycle indicators, and risk profiles
- **Class Imbalance Solution**: SMOTE oversampling increased minority class representation
- **Hyperparameter Optimization**: RandomizedSearchCV fine-tuned model parameters
- **Ensemble Methods**: Voting classifiers for more robust predictions
- **Model Stability**: Cross-validation ensures consistent performance across data splits

### Business Impact
- **Better Churn Detection**: 73% of churning customers now identified (vs 56% baseline)
- **Actionable Insights**: Advanced features reveal customer value and risk patterns
- **Production Ready**: Complete model package with preprocessing and validation
- **Scalable Pipeline**: Automated workflow for model retraining and deployment

## ï¿½ğŸ”„ Future Improvements

1. **Deep Learning Models**: Experiment with neural networks for pattern detection
2. **Time Series Analysis**: Incorporate temporal patterns in customer behavior
3. **External Data**: Include economic indicators, competitor analysis
4. **Real-time Scoring**: Implement streaming prediction pipeline
5. **Automated Feature Selection**: Use genetic algorithms for optimal feature sets
6. **Model Interpretability**: Implement SHAP values for better explainability

## ğŸ¤ Contributing

This project was developed as a complete data science workflow demonstration. Feel free to:
- Experiment with different models
- Add new features
- Improve preprocessing steps
- Enhance business insights

## ğŸ“„ License

This project is under the MIT license.

---

*Project completed using industry-standard data science practices with focus on business value and actionable insights. Advanced modeling techniques achieved 4% performance improvement with robust validation and production-ready deployment.*
